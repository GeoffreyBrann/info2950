{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "wRC+ Final Model: wRC_Plus ~ exit_velocity_avg + launch_angle_avg + barrels + poorlytopped_percent + hard_hit_percent + oz_swing_percent + out_zone + edge + groundballs_percent + flyballs_percent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "wOBA Final Model: xwOBA ~ exit_velocity_avg + launch_angle_avg + barrels + solidcontact_percent + poorlytopped_percent + hard_hit_percent + out_zone + oz_swing_percent + edge + groundballs_percent + flyballs_percent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Our Model Selection Process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, we combined the data from all five years (2015-2019) to form one pooled dataset in order to have the largest possible sample size for our analysis. We made a list of all predictor variables of interest which we could possibly include in our models. Then we examined scatterplots of the response variable (OPS+ or wOBA, etc.) vs. each predictor. After studying the scatterplots, we created an initial model with the predictors which seemed to have a significant relationship with the response. In this part, we were fairly liberal in adding predictors to the model, except that we avoided variables which were clearly redundant (barrels and barrel_batted_rate, for example). After we obtained our initial model, we tested its significance by obtaining the t-values and p-values of each predictor's slope coefficient. We then created a reduced model, removing terms which seemed to be unnecessary based on their p-values. We tested if there was any significant difference between the reduced model and the original model using an ANOVA test. If there did appear to be a significant difference between the two models based on the ANOVA test, then we created a larger reduced model in which we added one of the originally removed predictors to the original reduced model. If we concluded based on the ANOVA test that there was no significant difference between the two models, then we could proceed with the reduced model. We then examined the t-values and p-values of the reduced model. If all terms seemed to be necessary, we kept this model as the final model. If there were some terms which might not have been necessary, we continued with the process described above, creating another reduced model and performing another ANOVA test. We continued to do these steps until we found a final model in which all the predictors were necessary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}